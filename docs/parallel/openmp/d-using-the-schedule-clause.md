---
title: D. Schedule 子句
ms.date: 01/22/2019
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: 89e011784c5cccedc4a75f38d553458ea2e5d7e0
ms.sourcegitcommit: 382e247c0f1b4cb7c2dab837b8b6fdff24bff47a
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 01/28/2019
ms.locfileid: "55087283"
---
# <a name="d-the-schedule-clause"></a>D. Schedule 子句

并行区域具有至少一个屏障，在其末尾，并可能具有其他障碍，在其中。 在每个屏障的其他团队成员必须等待要到达的最后一个线程。 为了尽量减少这段等待时间，以便所有线程都到达屏障在了解同一时间应分发共享的工作。 如果共享的一些工作将包含在`for`构造，`schedule`子句可用于此目的。

重复地的引用同一对象，所选的计划时`for`构造可能主要由内存系统，如的存在性和大小的缓存，以及内存访问时间是统一的特征或nonuniform。 此类注意事项可能会使更希望能一致地指一组相同的一系列循环中的数组元素的每个线程，即使某些线程分配某些循环中的工作相对较少。 此安装程序可以通过使用`static`计划，其中的所有循环相同的边界。 在以下示例中，使用零作为在第二个循环中，下限即使`k`会更自然，如果计划不重要。

```cpp
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

在剩余的示例中，假定该内存访问不是主要考虑因素。 除非另行说明，否则所有线程都接收可比较的计算资源。 在这些情况下，选择的计划`for`构造取决于要执行之间紧靠在前面的所有共享工作和隐式的关闭屏障的障碍或最近的即将推出的屏障，如果没有`nowait`子句。 对于每个类型的计划，简短的示例演示如何计划该类很可能是最佳选择。 简要介绍遵循每个示例。

`static`日程安排也是适用于简单的情况下，并行区域包含单个`for`构造，每次迭代时需要相同数量的工作。

```cpp
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

`static`计划来定义特征的属性的每个线程将获得大约相同的迭代次数与任何其他线程和每个线程可以独立地确定分配给它的迭代。 因此没有进行的同步所需分发工作，并在每次迭代需要相同数量的工作的假设，所有线程应都完成在大约在同一时间。

团队*p*线程，让*ceiling(n/p)* 是整数*q*，以及满足*n = p\*q-r*与*0 < = r < p*。 一种实现`static`计划为此示例会将分配*q*与第一个迭代*p-1*线程，和*q r*到最后一个线程的迭代。  另一个可接受的实现会将分配*q*与第一个迭代*p-r*线程，并*q-1*到剩余迭代*r*线程。 此示例说明了为什么程序不应依赖于特定实现的详细信息。

`dynamic`计划的情况下适合`for`构造与要求不同，或甚至不可预见的工作量的迭代。

```cpp
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

`dynamic`计划的特征是没有线程在等待在屏障的长度超过它采用另一个线程来执行其最后一个迭代的属性。 此要求意味着迭代必须分配一次一个地在变得可用，它包含针对每个分配的同步线程。 通过指定最小块区大小可以降低同步开销*k*大于 1，以便分配的线程*k*一次直到少于*k*保持状态。 这可确保没有线程在等待在超过所需另一个线程 （至少） 执行它最终块屏障*k*迭代。

`dynamic`计划会很有用线程都将接收不同的计算资源，具有不同数量的每个迭代的工作的效果大体相同。 同样，动态计划也可以是线程到达的情况下很有用`for`在不同的时间，但在某些情况下构造`guided`计划可能更可取。

`guided`计划在不同时间，可能会到达线程的情况下适合`for`构造具有相同数量的工作有关需要每个迭代。 如果，则可能发生这种情况下，例如`for`构造会跟有一个或多个部分或`for`构造替换`nowait`子句。

```cpp
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

像`dynamic`，则`guided`计划保证没有线程在等待在超过所需另一个线程来执行其最后一个迭代，或最后一个屏障*k*迭代如果的区块大小为*k*指定。 在这种日程表之间`guided`计划特征的属性，它需要最少的同步。 块区大小*k*，一个典型的实现会将分配*q = ceiling(n/p)* 迭代可在第一个可用线程，设置*n*较大的*n-q*并*p\*k*，并重复，直到所有迭代都分配。

当选择最佳的计划不是因为对于这些示例，它是以明文`runtime`计划为试验不同的计划和块区大小而无需修改和重新编译该程序提供方便。 它时也会有用最佳的计划 （在某些可预测的方式） 依赖于向其应用程序的输入数据。

若要查看不同的计划之间权衡的示例，请考虑共享八个线程间的 1000年次迭代。 假设存在的每个迭代中固定工作量并将其用作时间单位。

如果所有线程都启动一次`static`计划将导致构造来执行以 125 单位，不进行同步。 但是，假设一个线程是较晚的到达的 100 个单位。 然后，剩余的七个线程会等待 100 个单位，屏障，并为整个构造执行时间将增加到 225。

因为同时`dynamic`和`guided`计划确保没有线程等待多个单位处屏障，延迟的线程导致构造来提高仅为 138 单位，从延迟可能增加其执行时间同步。 如果此类延迟不是可以忽略不计，它将成为重要的同步数是 1000年`dynamic`，但对于唯一 41 `guided`，假设一个的默认块区大小。 块区大小为 25，`dynamic`和`guided`两者分别完成 150 个单位，以及从所需同步时，只有 40 个和 20 的现在数的任何延迟。
