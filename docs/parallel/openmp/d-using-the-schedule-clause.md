---
description: 了解更多： D。Schedule 子句
title: D. schedule 子句
ms.date: 01/22/2019
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: bd1bb4f9a6c661205e2e647fc9e45d81903008c8
ms.sourcegitcommit: d6af41e42699628c3e2e6063ec7b03931a49a098
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 12/11/2020
ms.locfileid: "97342486"
---
# <a name="d-the-schedule-clause"></a>D. schedule 子句

一个并行区域的一端至少具有一个关卡，并可能会在其中产生额外的障碍。 在每个屏障上，团队的其他成员必须等待最后一个线程到达。 为了最大限度地缩短此等待时间，应分布共享工作，以便所有线程在同一时间到达关卡。 如果构造中包含某些共享工作 `for` ，则 `schedule` 可以使用子句来实现此目的。

当对相同对象进行重复引用时， `for` 可以根据内存系统的特征来确定构造的计划，如缓存的状态和大小，以及内存访问时间是统一的还是非一致性的。 此类注意事项可以使每个线程在一系列循环中一致地引用数组的同一组元素，即使某些线程在某些循环中分配的工作量相对较少。 可以通过对 `static` 所有循环使用具有相同边界的计划来完成此设置。 在下面的示例中，在第二个循环中将零用作下限，即使计划并不重要也是如此 `k` 。

```cpp
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

在其余的示例中，假定内存访问不是主要考虑因素。 除非另有说明，否则所有线程将接收可比较的计算资源。 在这些情况下，对构造的计划的选择 `for` 取决于要在最近的前述障碍之间执行的所有共享工作，以及隐含的关闭关卡或最近的即将到来的障碍（如果有子句） `nowait` 。 对于每种计划，一个简短的示例显示该计划类型可能是最佳选择。 每个示例都有一个简短讨论。

`static`计划还适用于最简单的情况，这是一个包含单一构造的并行区域 `for` ，每次迭代需要相同的工作量。

```cpp
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

`static`计划的特征是每个线程获取的迭代数大约与任何其他线程的迭代数相同，每个线程都可以独立确定分配给它的迭代数。 因此，无需同步即可分发工作，并且在每次迭代需要相同数量的工作时，所有线程都应在同一时间完成。

对于 *p* 线程团队，让 *天花板 (n/p)* 是整数 *q*，它满足 *n = p \* q-r* 与 *0 <= r < p*。 此示例的计划的一种实现方法是将 `static` *q* 迭代赋给第一个第 *1* 个线程，将 *q* 迭代赋给最后一个线程。  另一种可接受的实现会将 *q* 迭代赋给第一个 *p-r* 线程，将 *q-1* 次迭代分配给其余 *r* 线程。 此示例说明程序为什么不应依赖于特定实现的详细信息。

`dynamic`这种计划适用于带有迭代的情况 `for` ，这些迭代要求的工作数量变化，甚至是不可预测的。

```cpp
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

该 `dynamic` 计划的特征是，在该属性中，任何线程都不会在关卡上等待的时间比另一个线程执行其最终迭代的时间要长。 此要求意味着，每次都必须将迭代分配给线程，并为每个分配提供同步。 通过指定一个大于1的最小 *区块大小，* 可以减少同步开销，因此，每次将线程分配给 *k* ，直到仍不到 *k* 为止。 这可以保证在最多) *k* 次迭代时，任何线程都不会在关卡等待的时间长度超过另一个线程执行其最后 (块的时间。

`dynamic`如果线程接收了不同的计算资源，则计划可能会很有用，这与每个迭代的不同工作的效果几乎相同。 同样，如果线程在某些情况下到达构造，动态计划也会很有用 `for` ，但在某些情况下，可能会有更好的 `guided` 计划。

这 `guided` 种计划适用于这样的情况：线程可能会在构造中到达不同时间 `for` ，每次迭代都需要大约相同的工作量。 例如，如果 `for` 构造前面有一个或多个节或 `for` 构造 with 子句，就会发生这种情况 `nowait` 。

```cpp
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

与类似 `dynamic` ， `guided` 计划保证在关卡没有等待另一个线程执行其最终迭代时，或在指定了块大小 *k* 的情况下，不会等待关卡等待。 在此类计划中， `guided` 计划的特征是它需要最少的同步。 对于区块大小 *k*，典型实现会将 *q = 顶棚 (n/p)* 迭代分配给第一个可用线程，将 *n* 设置为 *n q* 和 *p \* k* 中的较大者，并重复，直到分配了所有迭代。

如果选择最佳计划并不像在这些示例中那样清晰，则 `runtime` 可以通过计划来试验不同的计划和区块大小，而无需修改和重新编译程序。 当最佳计划 (以某种可预测方式) 对应用程序的输入数据进行时，此方法也非常有用。

若要查看不同计划之间权衡的示例，请考虑在八个线程之间共享1000迭代。 假设每次迭代中有固定的工作量，并将其用作时间单位。

如果所有线程同时启动，则该 `static` 计划将导致构造在125单元中执行，而不进行同步。 但假设一个线程在到达后延迟为100个单元。 然后，剩余的七个线程在关卡等待100单位，整个构造的执行时间将增加到225。

由于 `dynamic` 和计划都 `guided` 确保没有线程等待关卡的多个单元，因此延迟的线程会使构造的执行时间仅增加到138个单位，这可能会由于同步延迟而增加。 如果此类延迟不能忽略不计，则很重要的是，同步的数量为 1000 `dynamic` ，但仅为 41 `guided` ，假设默认的块区大小为1。 块区大小为25， `dynamic` `guided` 两个单元均以150个单位完成，并加上所需同步所需的任何延迟，这种情况下，这两个延迟分别为40和20。
